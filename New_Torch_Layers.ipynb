{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["In this notebook, we introduce two novel layers tailored for convolutional neural networks (CNNs): the SplitLinear layers and DropNorm layer. These additions aim to enhance model performance and flexibility by offering specialized functionalities within the network architecture. Let's delve into their implementation and explore their potential benefits for various CNN applications."],"metadata":{"id":"FQ4nvw6s9u5A"}},{"cell_type":"markdown","source":["# **Introducing the SplitLinear layer**"],"metadata":{"id":"qrxAF3zM9ONL"}},{"cell_type":"markdown","source":["The SplitLinear class represents a custom PyTorch layer designed to process 2D tensors by splitting them along the feature dimension. Upon initialization, it creates a linear layer and an activation function (ReLU). During the forward pass, the input tensor is split into two halves along the feature dimension. Each split tensor then undergoes the same linear transformation using the shared linear layer. Subsequently, the ReLU activation function is applied to both transformed tensors independently. Finally, the resulting tensors are concatenated along the feature dimension to produce the output tensor. The linear layer parameters are initialized using random numbers in a specified range, determined by the number of input features. This approach enables efficient processing of high-dimensional data while promoting flexibility and expressive power in modeling complex relationships."],"metadata":{"id":"idzgJjFC9Mpb"}},{"cell_type":"markdown","source":["![SplitLinear layer block diagram.png](data:image/png;base64,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)"],"metadata":{"id":"p32x9Q9r9ykf"}},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n"],"metadata":{"id":"rCQtXSZu-Sgn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Set device to calculate on\n","if torch.cuda.is_available():\n","    device = torch.device(\"cuda\")\n","else:\n","    device = torch.device(\"cpu\")"],"metadata":{"id":"clkPPucjhJ1k"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"O2G3bnu-8jdo"},"outputs":[],"source":["class SplitLinear:\n","    \"\"\"\n","    A custom PyTorch layer designed to process 2D tensors by splitting them along the feature dimension,\n","    passing each split through a shared linear layer followed by a ReLU activation function, and then\n","    recombining the results.\n","\n","    Args:\n","        in_features (int): Number of input features.\n","\n","    Attributes:\n","        in_features (int): Number of input features.\n","        linear_layer (torch.nn.Linear): Linear layer for processing split tensors.\n","        activation_layer (torch.nn.ReLU): ReLU activation function.\n","\n","    Methods:\n","        forward(tensor_in): Performs a forward pass through the SplitLinear layer.\n","        split_tensor(tensor_in): Splits the input tensor into two tensors along the feature dimension.\n","        generate_uniform_numbers_in_range(k, size): Generates uniform random numbers in a specified range.\n","\n","    \"\"\"\n","\n","    def __init__(self, in_features):\n","        \"\"\"\n","        Initializes the SplitLinear layer with the specified number of input features.\n","\n","        Args:\n","            in_features (int): Number of input features.\n","\n","        \"\"\"\n","        self.in_features = in_features\n","        self.linear_layer = nn.Linear(in_features // 2, in_features // 2)\n","        self.__init_params()\n","        self.activation_layer = nn.ReLU()\n","\n","    def forward(self, tensor_in):\n","        \"\"\"\n","        Performs a forward pass through the SplitLinear layer.\n","\n","        Args:\n","            tensor_in (torch.Tensor): Input tensor.\n","\n","        Returns:\n","            torch.Tensor: Output tensor after processing through the SplitLinear layer.\n","\n","        \"\"\"\n","        print(\"Original tensor:\", tensor_in, sep=\"\\n\", end=\"\\n\\n\")\n","\n","        left, right = self.split_tensor(tensor_in)\n","        print(\"The original tensor was divided into two new tensors:\", left, right, sep=\"\\n\", end=\"\\n\\n\")\n","\n","        left = self.linear_layer(left)\n","        right = self.linear_layer(right)\n","        print(\"The new tensors passed through the same linear layer:\", left, right, sep=\"\\n\", end=\"\\n\\n\")\n","\n","        left = self.activation_layer(left)\n","        right = self.activation_layer(right)\n","        print(\"Ultimately, the tensors underwent the ReLU activation:\", left, right, sep=\"\\n\", end=\"\\n\\n\")\n","\n","        res = torch.cat([left, right], dim=1)\n","        print(\"Combining the two resultant tensors yields:\\n\", res, end=\"\\n\\n\")\n","\n","        return res\n","\n","\n","    @staticmethod\n","    def split_tensor(tensor_in):\n","        \"\"\"\n","        Splits the input tensor into two tensors along the feature dimension.\n","\n","        Args:\n","            tensor_in (torch.Tensor): Input tensor.\n","\n","        Returns:\n","            torch.Tensor: Left split tensor.\n","            torch.Tensor: Right split tensor.\n","\n","        \"\"\"\n","        split_idx = tensor_in.size()[1] // 2\n","        left = tensor_in[:, :split_idx]\n","        right = tensor_in[:, split_idx:]\n","        return left, right\n","\n","    @staticmethod\n","    def generate_uniform_numbers_in_range(k, size):\n","        \"\"\"\n","        Generates uniform random numbers in the range [-k, k].\n","\n","        Args:\n","            k (float): Scaling factor for the range.\n","            size (tuple): Size of the tensor to be generated.\n","\n","        Returns:\n","            torch.Tensor: Tensor of uniform random numbers in the range [-k, k].\n","\n","        \"\"\"\n","        uniform_numbers = torch.rand(size)\n","        scaled_numbers = 2 * k * (uniform_numbers - 0.5)\n","        return scaled_numbers\n","\n","    def __init_params(self):\n","        \"\"\"\n","        Initializes the parameters of the linear layer using random numbers in the range [-k_in^(-0.5), k_in^(-0.5)],\n","        where k_in is the number of inputs of the linear layer.\n","\n","        \"\"\"\n","\n","        k = (0.5 * self.in_features) ** (-0.5)  # linear_layer_in_features^-0.5\n","        linear_layer_size = self.in_features // 2\n","        size = (linear_layer_size, linear_layer_size + 1)  # +1 for bias\n","        uniform_numbers_in_range = self.generate_uniform_numbers_in_range(k, size)\n","\n","        with torch.no_grad():\n","            weight_init = uniform_numbers_in_range[:, :-1]\n","            bias_init = uniform_numbers_in_range[:, -1]\n","            self.linear_layer.weight = nn.Parameter(weight_init)\n","            self.linear_layer.bias = nn.Parameter(bias_init)\n"]},{"cell_type":"markdown","source":["I initialized the layer parameters similarly to how torch.nn.Linear initializes its parameters"],"metadata":{"id":"W_vG_XAnYjfR"}},{"cell_type":"markdown","source":["Let's delve into the operations of the SplitLinear layer by creating an instance of the class and examining its behavior on a sample tensor"],"metadata":{"id":"4eZVi3yD-cK7"}},{"cell_type":"code","source":["layer = SplitLinear(6)\n","C = torch.arange(30,dtype=torch.float32).reshape(5,6)\n"],"metadata":{"id":"kAkfvbKg--cH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["layer.forward(C);"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_dNtYtcb_BQX","outputId":"1750c353-a91d-4119-f837-182dd6a697f9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Original tensor:\n","tensor([[ 0.,  1.,  2.,  3.,  4.,  5.],\n","        [ 6.,  7.,  8.,  9., 10., 11.],\n","        [12., 13., 14., 15., 16., 17.],\n","        [18., 19., 20., 21., 22., 23.],\n","        [24., 25., 26., 27., 28., 29.]])\n","\n","The original tensor was divided into two new tensors:\n","tensor([[ 0.,  1.,  2.],\n","        [ 6.,  7.,  8.],\n","        [12., 13., 14.],\n","        [18., 19., 20.],\n","        [24., 25., 26.]])\n","tensor([[ 3.,  4.,  5.],\n","        [ 9., 10., 11.],\n","        [15., 16., 17.],\n","        [21., 22., 23.],\n","        [27., 28., 29.]])\n","\n","The new tensors passed through the same linear layer:\n","tensor([[-0.5322, -0.5938,  1.1930],\n","        [-0.5857, -0.8823, 11.2780],\n","        [-0.6392, -1.1709, 21.3631],\n","        [-0.6927, -1.4594, 31.4482],\n","        [-0.7461, -1.7479, 41.5332]], grad_fn=<AddmmBackward0>)\n","tensor([[-0.5589, -0.7381,  6.2355],\n","        [-0.6124, -1.0266, 16.3206],\n","        [-0.6659, -1.3151, 26.4056],\n","        [-0.7194, -1.6036, 36.4907],\n","        [-0.7729, -1.8922, 46.5757]], grad_fn=<AddmmBackward0>)\n","\n","Ultimately, the tensors underwent the ReLU activation:\n","tensor([[ 0.0000,  0.0000,  1.1930],\n","        [ 0.0000,  0.0000, 11.2780],\n","        [ 0.0000,  0.0000, 21.3631],\n","        [ 0.0000,  0.0000, 31.4482],\n","        [ 0.0000,  0.0000, 41.5332]], grad_fn=<ReluBackward0>)\n","tensor([[ 0.0000,  0.0000,  6.2355],\n","        [ 0.0000,  0.0000, 16.3206],\n","        [ 0.0000,  0.0000, 26.4056],\n","        [ 0.0000,  0.0000, 36.4907],\n","        [ 0.0000,  0.0000, 46.5757]], grad_fn=<ReluBackward0>)\n","\n","Combining the two resultant tensors yields:\n"," tensor([[ 0.0000,  0.0000,  1.1930,  0.0000,  0.0000,  6.2355],\n","        [ 0.0000,  0.0000, 11.2780,  0.0000,  0.0000, 16.3206],\n","        [ 0.0000,  0.0000, 21.3631,  0.0000,  0.0000, 26.4056],\n","        [ 0.0000,  0.0000, 31.4482,  0.0000,  0.0000, 36.4907],\n","        [ 0.0000,  0.0000, 41.5332,  0.0000,  0.0000, 46.5757]],\n","       grad_fn=<CatBackward0>)\n","\n"]}]},{"cell_type":"markdown","source":["# **Layer Analysis**"],"metadata":{"id":"yP25QF1Z_DJm"}},{"cell_type":"markdown","source":["## Number of parameters"],"metadata":{"id":"ektlNMnC_Eml"}},{"cell_type":"markdown","source":["In a standard linear layer operating on a tensor of size N x M, the parameters of the linear layer can be expressed as $N_1 = M \\cdot M + M  = M^2 + M$.\n","\n","However, in our linear layer, the input dimensions for the linear layer are halved, resulting in M/2. Consequently, the number of parameters for the linear layer within the SplitLinear layer becomes $N_2 = \\frac{M}{2} ⋅ \\frac{M}{2} + \\frac{M}{2} = \\frac{M^2}{4} + \\frac{M}{2}$.\n","\n","Thus, the ratio between this cases is: in parameters between our layer and the standarnumber of parameters between this cases: $\\frac{N_1} {N_2} = \\frac{M (M+1)}{\\frac{M}{2}(\\frac{M}{2}+1)}=2\\frac{M+1}{\\frac{M}{2}+1} = 2(\\frac{ \\frac{M}{2}+1}{\\frac{M}{2}+1}+\\frac{\\frac{M}{2}} {\\frac{M}{2}+1})= 2(1+\\frac{\\frac{M}{2}}{\\frac{M}{2}+1}) $, approaches 4 when M is large.\n","Therfore using the new layer helps with parameters reduction."],"metadata":{"id":"7sm_OW8b_GxD"}},{"cell_type":"markdown","source":["## Layer Parameter Gradient Analysis"],"metadata":{"id":"fbha3Awh_ISL"}},{"cell_type":"markdown","source":["We assume that the gradient of the loss function with respect to the outputs is given as $\\frac{\\partial{C}}{\\partial{Y}}$. Our objective is to calculate the gradient of the loss function with respect to the layer parameters using the chain rule.\n","\n","Let's denote the input tensor $X$, which is split into two parts, $X_1$ and $X_2$, along the feature dimension. These parts represent the input to the linear layer:\n","\\begin{align}\n","  X = \\begin{bmatrix}\n","          x_{0} \\\\\n","          x_{1} \\\\\n","          \\vdots \\\\\n","          x_{m-1}\n","        \\end{bmatrix}\n","    =\n","        \\begin{bmatrix}\n","          X_{1} \\\\\n","          X_{2}\n","        \\end{bmatrix} \\in R^M\n","\\end{align}\n","\n","Next, we express the outputs of the linear layer as $Z_1$ and $Z_2$:\n","\n","\\begin{align}\n","  Z_1=WX_1 + b ,\\hspace{0.5cm} Z_2=WX_2 + b\n","\\end{align} \\\n"," where $W \\in R^{\\frac{M}{2} \\times \\frac{M}{2}}$ and $b \\in R^\\frac{M}{2}$ are the weights and biases of the linear layer, respectively. Therefore, $Z_1$, $Z_2$ ∈ $R^\\frac{M}{2}$. \\\n","We also define $Z$ as the concatenation of $Z_1$ and $Z_2$, representing the total output of the linear layer.\n","\n","\\begin{align}\n","  Z = \\begin{bmatrix}\n","          z_{0} \\\\\n","          z_{1} \\\\\n","          \\vdots \\\\\n","          z_{m-1}\n","        \\end{bmatrix}\n","    =\n","        \\begin{bmatrix}\n","          Z_{1} \\\\\n","          Z_{2}\n","        \\end{bmatrix} \\in R^M\n","\\end{align}\n","\n","\n","The results of the activation layer are given by $Y_1 = ReLU(Z_1)$ and $Y_2 = ReLU(Z_2)$, where $Y_1, Y_2 \\in R^\\frac{M}{2}$.\n","\n","Thus, the total output of the layer is denoted as:\n","\\begin{align}\n","  Y =\n","        \\begin{bmatrix}\n","          y_0 \\\\\n","          y_1 \\\\\n","          \\vdots \\\\\n","          y_{m-1}\n","        \\end{bmatrix}\n","        =\n","        \\begin{bmatrix}\n","          Y_{1} \\\\\n","          Y_{2}\n","        \\end{bmatrix}\n","        \\in R^M\n","\\end{align}\n","\n","Assuming that $\\frac{\\partial{C}}{\\partial{Y}}$ is given as:\n","\\begin{align}\n","  \\frac{\\partial{C}}{\\partial{Y}} =  \n","  \\begin{bmatrix}\n","    \\frac{\\partial{C}}{\\partial{Y_1}}\\\\\n","    \\frac{\\partial{C}}{\\partial{Y_2}}\n","  \\end{bmatrix}\n","     =\n","  \\begin{bmatrix}\n","    \\frac{\\partial{C}}{\\partial{y_0}}\\\\\n","    \\vdots \\\\\n","    \\frac{\\partial{C}}{\\partial{y_{M-1}}}\n","  \\end{bmatrix}\n","\\end{align}\n","\n","Our goal is to calculate the gradient of the cost function. Using the chain rule, we obtain:\n","\n","\\begin{align}\n","  \\frac{\\partial{C}}{\\partial{W}} = \\frac{\\partial{C}}{\\partial{Y}}  \\frac{\\partial{Y}}{\\partial{Z}} \\frac{\\partial{Z}}{\\partial{W}}  \n","\\end{align}\n","\n","\\\n","For $k \\in \\{1,2\\}$:\n","\\begin{align*}\n","\\frac{\\partial{Z_{k,i}}}{\\partial{W_{ij}}} &= \\frac{\\partial{z_{(k-1)⋅\\frac{M}{2} + i}}}{\\partial{W_{ij}}} = \\frac{\\partial{\\sum_{n=0}^{\\frac{M}{2}} W_{in} \\cdot X_{k,n}}+b_n}{\\partial{W_{ij}}} = x_{(k-1)⋅\\frac{M}{2} + j} \\\\\n","\\frac{\\partial{Z_{k,i}}}{\\partial{b_{i}}} &= \\frac{\\partial{z_{(k-1)⋅\\frac{M}{2} + i}}}{\\partial{b_{i}}} = \\frac{\\partial{\\sum_{n=0}^{\\frac{M}{2}} W_{in} \\cdot X_{k,n}}+b_n}{\\partial{b_{i}}} = 1 \\\\\n","\\frac{\\partial{Y_{k,i}}}{\\partial{Z_{k,i}}} &= \\frac{\\partial{y_{(k-1)⋅\\frac{M}{2} + i}}}{\\partial{z_{(k-1)⋅\\frac{M}{2} + i}}} = \\frac{\\partial{ReLU(z_{(k-1)⋅\\frac{M}{2} + i})}}{\\partial{z_{(k-1)⋅\\frac{M}{2} + i}}} = 1\\{z_{(k-1)⋅\\frac{M}{2} + i} ≥ 0\\}\n","\\end{align*}\n","\n","where:\n","\\begin{align*}\n","X_{k,j} &= x_{(k-1)⋅\\frac{M}{2} + j}\n","\\end{align*}\n","\n","\\\n","Additionally:\n","\\begin{align*}\n","\\frac{\\partial{Z_{k,l}}}{\\partial{W_{ij}}} &= 0, \\quad \\frac{\\partial{Z_{k,l}}}{\\partial{b_{i}}} = 0 \\quad \\text{for} \\quad l \\neq i, \\quad k \\in \\{1,2\\}\n","\\end{align*}\n","\n","Therefore, we have:\n","\\begin{align*}\n","\\frac{\\partial{Y_{k,l}}}{\\partial{W_{ij}}} &= \\frac{\\partial{Y_{k,l}}}{\\partial{Z_{k,l}}}\\frac{\\partial{Z_{k,l}}}{\\partial{W_{ij}}} = 0 \\quad \\text{for} \\quad l \\neq i, \\quad k \\in \\{1,2\\} \\\\   \n","\\frac{\\partial{Y_{k,l}}}{\\partial{b_{i}}} &= \\frac{\\partial{Y_{k,l}}}{\\partial{Z_{k,l}}}\\frac{\\partial{Z_{k,l}}}{\\partial{b_{i}}} = 0 \\quad \\text{for} \\quad l \\neq i, \\quad k \\in \\{1,2\\}\n","\\end{align*}\n","\n","Summing it all up:\n","\\begin{align}\n","\\frac{\\partial{C}}{\\partial{W_{ij}}} &= \\frac{\\partial{C(Y_1,Y_2)}}{\\partial{W_{ij}}} = \\frac{\\partial{C}}{\\partial{Y_1}}\\frac{\\partial{Y_1}}{\\partial{W_{ij}}} + \\frac{\\partial{C}}{\\partial{Y_2}}\\frac{\\partial{Y_2}}{\\partial{W_{ij}}} \\\\\n","&= \\frac{\\partial{C}}{\\partial{Y_1}}\\frac{\\partial{Y_1}}{\\partial{Z}_1} \\frac{\\partial{Z}_1}{\\partial{W_{ij}}} + \\frac{\\partial{C}}{\\partial{Y_2}}\\frac{\\partial{Y_2}}{\\partial{Z}_2} \\frac{\\partial{Z}_2}{\\partial{W_{ij}}} \\\\\n","&= \\frac{\\partial{C}}{\\partial{Y_{1,i}}}\\frac{\\partial{Y_{1,i}}}{\\partial{Z}_{1,i}} \\frac{\\partial{Z}_{1,i}}{\\partial{W_{ij}}} +\\frac{\\partial{C}}{\\partial{Y_{2,i}}}\\frac{\\partial{Y_{2,i}}}{\\partial{Z}_{2,i}} \\frac{\\partial{Z}_{2,i}}{\\partial{W_{ij}}} \\\\\n","&= \\sum_{k=1}^{2}\\frac{\\partial{C}}{\\partial{y_{(k-1)\\frac{M}{2}j}}}x_{(k-1)\\frac{M}{2}+j} \\cdot 1\\{z_{(k-1)\\frac{M}{2}+i}\\} \\\\\n","&= \\sum_{k=1}^{2}\\frac{\\partial{C}}{\\partial{y_{(k-1)\\frac{M}{2}+j}}}x_{(k-1)\\frac{M}{2}+j} \\cdot 1\\{W_i \\cdot X_k + b_i \\ge 0\\}\n","\\end{align}\n","\n","Similarly:\n","\\begin{align}\n","\\frac{\\partial{C}}{\\partial{b_{i}}} &= \\frac{\\partial{C}}{\\partial{Y_{1,i}}}\\frac{\\partial{Y_{1,i}}}{\\partial{Z}_{1,i}} \\frac{\\partial{Z}_{1,i}}{\\partial{b_{i}}} +\\frac{\\partial{C}}{\\partial{Y_{2,i}}}\\frac{\\partial{Y_{2,i}}}{\\partial{Z}_{2,i}} \\frac{\\partial{Z}_{2,j}}{\\partial{b_{i}}} \\\\\n","&= \\sum_{k=1}^{2}\\frac{\\partial{C}}{\\partial{y_{(k-1)\\frac{M}{2}+i}}} \\cdot 1\\{W_i \\cdot X_k + b_i \\ge 0\\}\n","\\end{align}\n","\n"],"metadata":{"id":"ZBStpUhKKSgA"}},{"cell_type":"markdown","source":["If the input were to be split into 4 parts instead of 2, the gradient would look like this:"],"metadata":{"id":"UeyD5Cv_RCtx"}},{"cell_type":"markdown","source":["\\begin{align}\n","\\frac{\\partial{C}}{\\partial{W_{ij}}} = \\sum_{k=1}^{4}\\frac{\\partial{C}}{\\partial{y_{(k-1)\\frac{M}{4}+j}}}x_{(k-1)\\frac{M}{4}+j} \\cdot 1\\{W_i \\cdot X_k + b_i \\ge 0\\}\n","\\end{align}\n","\n","\\begin{align}\n","\\frac{\\partial{C}}{\\partial{b_{i}}} &= \\sum_{k=1}^{4}\\frac{\\partial{C}}{\\partial{y_{(k-1)\\frac{M}{4}+i}}} \\cdot 1\\{W_i \\cdot X_k + b_i \\ge 0\\}\n","\\end{align}\n"],"metadata":{"id":"iBQQPyo8NsMP"}},{"cell_type":"markdown","source":["# **Introducing the DropNorm layer**"],"metadata":{"id":"itlLj3Br_Ubz"}},{"cell_type":"markdown","source":["In this section, we'll explore the implementation and integration of a custom layer called DropNorm into a Convolutional Neural Network (CNN) for image classification. The DropNorm layer combines the concepts of dropout and sample normalization to enhance the performance and stability of the network during training."],"metadata":{"id":"72Y-P18L_Zpv"}},{"cell_type":"markdown","source":["**Understanding DropNorm**\n","\n","1. Dropout: Dropout randomly sets a fraction of input features to zero during each training iteration, effectively regularizing the network and preventing overfitting. This encourages the network to learn more robust features by reducing co-adaptation between neurons.\n","\n","2. Normalization: Sample normalization normalizes the activations of each layer, stabilizing the training process and accelerating convergence. By centering and scaling the activations, batch normalization ensures that the network learns more smoothly and efficiently"],"metadata":{"id":"kuMY1SWn_dCc"}},{"cell_type":"code","source":["import torchvision\n","import torchvision.transforms as transforms\n","import torch.optim as optim\n","import torch.nn.functional as F"],"metadata":{"id":"KT78ieBS_ecz"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["To introduce variability and randomness into our models, we often need to generate random numbers. However, in certain scenarios, we may require a set of unique random numbers. The get_k_different_random_numbers function serves this purpose by generating K different random numbers within a specified range. We will utilize this function to select the entries to drop during dropout, ensuring that each dropout operation selects a unique set of activations for regularization."],"metadata":{"id":"4B6sRJ_0_iSz"}},{"cell_type":"code","source":["def get_k_different_random_numbers(k, t):\n","    \"\"\"\n","    Generates k different random numbers in the range 0 to t-1.\n","\n","    Args:\n","        k (int): Number of random numbers to generate.\n","        t (int): Upper bound of the range (exclusive).\n","\n","    Returns:\n","        torch.Tensor: A tensor containing k different random numbers.\n","\n","    Raises:\n","        ValueError: If k or t is not an integer or if either k or t is less than 0, or if k is greater than t.\n","    \"\"\"\n","    if not isinstance(k, int) or k < 0:\n","        raise ValueError(\"k must be a non-negative integer.\")\n","\n","    if not isinstance(t, int) or t < 0:\n","        raise ValueError(\"t must be a non-negative integer.\")\n","\n","    if k > t:\n","        raise ValueError(\"k must be less than or equal to t.\")\n","\n","    # Generate a random permutation of integers from 0 to t-1\n","    permutation = torch.randperm(t)\n","\n","    # Select the first k elements to get k different random numbers\n","    return permutation[:k]\n"],"metadata":{"id":"U5PTfus3_hof"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Example usage:\n","K = 5\n","T = 10\n","random_numbers = get_k_different_random_numbers(K, T)\n","print(\"K different random numbers in the range 0 to\", T-1, \":\", random_numbers)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Vy9wY_4p_lJ7","outputId":"63e4d3f0-5808-43c9-94cf-6434cedff7da"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["K different random numbers in the range 0 to 9 : tensor([8, 5, 0, 6, 1])\n"]}]},{"cell_type":"markdown","source":["When implementing dropout, we often need to create a mask of zeros and ones to randomly select which elements to keep and which to zero out. The create_tensor_from_random_numbers function facilitates this process by generating a mask tensor of a specified size. In this mask, zeros correspond to the indices where dropout will be applied, while ones indicate the elements that remain unchanged. To achieve randomness and uniqueness in selecting indices to drop, we leverage the get_k_different_random_numbers function introduced earlier."],"metadata":{"id":"P6QvPztt_pVK"}},{"cell_type":"code","source":["def create_dropout_mask(size, dropout_rate=0.5, dtype=torch.float32):\n","    \"\"\"\n","    Creates a dropout mask tensor of a specified size.\n","\n","    Args:\n","        size (tuple): The size of the output tensor.\n","        dropout_rate (float): The rate of zeros in the mask, indicating the dropout probability.\n","        dtype (torch.dtype, optional): The data type of the output tensor (default: torch.float32).\n","\n","    Returns:\n","        torch.Tensor: A tensor of the specified size with elements set to zero based on the dropout rate.\n","\n","    Note:\n","        The dropout rate specifies the probability of an element being set to zero (dropped out).\n","    \"\"\"\n","    # Calculate the total number of elements in the tensor\n","    t = 1\n","    for dim in size:\n","        t *= dim\n","\n","    # Calculate the number of elements to set to zero based on the dropout rate\n","    num_zeros = int(t * dropout_rate)\n","\n","    # Generate random indices for elements to be set to zero\n","    random_indices = get_k_different_random_numbers(num_zeros, t)\n","\n","    # Create a tensor filled with ones\n","    mask = torch.ones(size, dtype=dtype)\n","\n","    # Set the elements at random indices to zero\n","    mask.view(-1)[random_indices] = 0\n","\n","    return mask\n"],"metadata":{"id":"bQwwmNT6_qvp"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Subsequently, in our dropout implementation, we'll need to apply the dropout mask to the tensor along a specific axis, typically the batch axis. This ensures that the same dropout pattern is applied consistently to each sample within the batch. To achieve this, we've implemented the mask_tensor_along_axis function. This function efficiently applies a given mask to the tensor along the specified axis, maintaining the same dropout pattern across all samples in the batch."],"metadata":{"id":"wkO-P91V_rxP"}},{"cell_type":"code","source":["def mask_tensor_along_axis(mask, tensor, dim):\n","    \"\"\"\n","    Masks the tensor along a specific dimension using the mask.\n","\n","    Args:\n","        mask (torch.Tensor): A binary tensor indicating positions to keep (1) or discard (0).\n","        tensor (torch.Tensor): The tensor to be masked.\n","        dim (int): The dimension along which to apply the masking.\n","\n","    Returns:\n","        torch.Tensor: The masked tensor.\n","    \"\"\"\n","    # Set device to calculate on\n","    if torch.cuda.is_available():  # Check if GPU is available\n","        device = torch.device(\"cuda\")  # Set device to GPU\n","    else:\n","        device = torch.device(\"cpu\")  # Set device to CPU\n","\n","\n","\n","    tensor = tensor.to(device)\n","    if mask.dim() < tensor.dim():\n","        mask = mask.unsqueeze(dim)\n","\n","    mask = mask.to(device)\n","    # Multiply the tensor with the expanded result tensor to apply masking\n","    masked_tensor = tensor * mask\n","    return masked_tensor"],"metadata":{"id":"nyz-Yzi2_svK"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Usage example:"],"metadata":{"id":"pqvO-O_k_vuL"}},{"cell_type":"code","source":["s = torch.arange(120,dtype = torch.float32).reshape(2,3,4,5).to(device) # Create a tensor\n","shape = s.size()[1:] # Obtain shape of features\n","mask_ex = create_dropout_mask(shape, 0.5) # Create the dropout mask\n","masked = mask_tensor_along_axis(mask_ex, s, 0) # Mask the tensor along the batch dimension\n","masked"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DvZWT-O5_twi","outputId":"7ccdee01-4e41-4d68-b2f1-8b94f2b6cad4"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[[[  0.,   0.,   0.,   3.,   4.],\n","          [  0.,   0.,   7.,   0.,   0.],\n","          [ 10.,  11.,  12.,   0.,   0.],\n","          [ 15.,  16.,   0.,   0.,  19.]],\n","\n","         [[  0.,   0.,  22.,   0.,   0.],\n","          [  0.,  26.,  27.,  28.,   0.],\n","          [ 30.,  31.,   0.,  33.,  34.],\n","          [ 35.,  36.,  37.,  38.,  39.]],\n","\n","         [[  0.,   0.,  42.,   0.,   0.],\n","          [  0.,   0.,  47.,  48.,   0.],\n","          [ 50.,  51.,   0.,   0.,   0.],\n","          [ 55.,   0.,   0.,  58.,  59.]]],\n","\n","\n","        [[[  0.,   0.,   0.,  63.,  64.],\n","          [  0.,   0.,  67.,   0.,   0.],\n","          [ 70.,  71.,  72.,   0.,   0.],\n","          [ 75.,  76.,   0.,   0.,  79.]],\n","\n","         [[  0.,   0.,  82.,   0.,   0.],\n","          [  0.,  86.,  87.,  88.,   0.],\n","          [ 90.,  91.,   0.,  93.,  94.],\n","          [ 95.,  96.,  97.,  98.,  99.]],\n","\n","         [[  0.,   0., 102.,   0.,   0.],\n","          [  0.,   0., 107., 108.,   0.],\n","          [110., 111.,   0.,   0.,   0.],\n","          [115.,   0.,   0., 118., 119.]]]], device='cuda:0')"]},"metadata":{},"execution_count":11}]},{"cell_type":"markdown","source":["In our normalization process, we encounter the need to calculate the mean and variance of a tensor, excluding dropped elements indicated by a dropout mask. To address this requirement, we've implemented the calc_dropped_mean and calc_dropped_var functions. These functions enable us to compute the mean and variance along specified dimensions while disregarding dropped elements, facilitating the normalization process. By leveraging these functions, we ensure that the statistics calculated accurately reflect the distribution of the tensor, accounting for the dropout mechanism's impact."],"metadata":{"id":"fu_oABSf_xs-"}},{"cell_type":"code","source":["def calc_dropped_mean(x, mask, dims):\n","  \"\"\"\n","    Calculates the mean of the tensor x while disregarding dropped indices.\n","\n","    Args:\n","        x (torch.Tensor): The input tensor.\n","        mask (torch.Tensor): The dropout mask tensor.\n","\n","    Returns:\n","        torch.Tensor: The mean of the tensor x.\n","  \"\"\"\n","  num_non_dropped = torch.sum(mask)  # Count the number of non-dropped elements\n","  mean = torch.sum(x, dim=dims)/num_non_dropped  # mean = sum/num_elements\n","  return mean\n","\n","def calc_dropped_var(x,mask, dims):\n","  \"\"\"\n","    Calculates the variance of the tensor x while disregarding dropped indices.\n","\n","    Args:\n","        x (torch.Tensor): The input tensor.\n","        mask (torch.Tensor): The dropout mask tensor.\n","\n","    Returns:\n","        torch.Tensor: The variance of the tensor x.\n","  \"\"\"\n","  var = calc_dropped_mean(x**2, mask, dims)- calc_dropped_mean(x, mask, dims)**2 # variance(X) = mean(X^2) - mean^2(X)\n","  return var\n"],"metadata":{"id":"F_BHEaiA_zou"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["At certain points in our implementation, we may encounter the need to pad a tensor with singleton dimensions to match the number of dimensions of another tensor. This is where the dimensions_pad_as function comes into play. It takes two tensors as input: tensor_to_pad and tensor_like. The function calculates the difference in the number of dimensions between the two tensors and then expands tensor_to_pad accordingly by adding singleton dimensions. This ensures alignment between tensors, facilitating subsequent operations."],"metadata":{"id":"UOxWh0Lz_0uD"}},{"cell_type":"code","source":["def dimensions_pad_as(tensor_to_pad, tensor_like):\n","  \"\"\"\n","  Pads the input tensor with singleton dimensions to match the number of dimensions of another tensor.\n","\n","  Args:\n","      tensor_to_pad (torch.Tensor): The tensor to be padded.\n","      tensor_like (torch.Tensor): The tensor whose number of dimensions will be matched.\n","\n","  Returns:\n","      torch.Tensor: The padded tensor with the same number of dimensions as the tensor_like.\n","  \"\"\"\n","  # Determine the number of dimensions to unsqueeze\n","  num_dims_to_unsqueeze = tensor_like.dim() - tensor_to_pad.dim()\n","\n","  # Clone the input tensor\n","  tensor_expanded = tensor_to_pad.clone()\n","\n","  # Unsquueze singleton dimensions to match the number of dimensions of the tensor_like\n","  for _ in range(num_dims_to_unsqueeze):\n","      tensor_expanded = tensor_expanded.unsqueeze(dim=-1)\n","\n","  return tensor_expanded"],"metadata":{"id":"k0W8_bIu_1dD"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Now, let's delve into the non_zero_normalize function, a pivotal element of our normalization pipeline. This function takes a tensor as input and calculates the mean and variance while disregarding dropped values, considering a dropout mask if provided. It relies on calc_dropped_mean and calc_dropped_var to compute the statistics along the specified dimensions, excluding dropped elements indicated by the mask. After computing the mean and variance, it normalizes the input tensor using the formula (x - mean) / sqrt(variance + eps), where eps is a minute constant added to prevent division by zero. This normalization ensures that each entry in the tensor, along the specified dimensions, is scaled according to its deviation from the mean, while dropped elements are substituted with zeros."],"metadata":{"id":"vz7tqLs-_2X5"}},{"cell_type":"code","source":["def non_zero_normalize(x, mask=None, dims=None, eps=1e-5):\n","    \"\"\"\n","    Normalizes the input tensor while ignoring NaN values.\n","\n","    Args:\n","        x (torch.Tensor): The input tensor.\n","        eps (float, optional): A small constant added to the variance to avoid division by zero.\n","        mask (torch.Tensor, optional): The mask tensor indicating dropped elements.\n","        dims (int or tuple of ints, optional): The dimensions along which to compute the normalization.\n","            If None (default), normalization is performed along all dimensions except the first.\n","\n","    Returns:\n","        torch.Tensor: The normalized tensor.\n","\n","    Note:\n","        NaN values are ignored during computation.\n","        If `mask` is not provided, all elements are considered in the normalization.\n","        If `dims` is None, normalization is performed along all dimensions except the first (batch dimension).\n","\n","    Implementation Details:\n","        - If `dims` is None, `dims` is set to all dimensions except the first (batch dimension).\n","        - Calculate the mean and variance along the specified dimensions using the `calc_dropped_mean` and `calc_dropped_var` functions.\n","        - Pad the mean and variance tensors to match the original tensor's number of dimensions using the `dimensions_pad_as` function.\n","        - Normalize the original tensor using the computed mean and variance, with a small constant (`eps`) added to the variance to avoid division by zero.\n","        - Replace dropped elements with zeros.\n","    \"\"\"\n","    if dims is None:\n","        dims = tuple(range(1, x.dim()))  # Default: all dimensions except the first (batch dimension)\n","    if mask is None:\n","        mask = torch.ones_like(x)  # Default: no elements dropped\n","\n","\n","\n","    # Calculate the mean and variance while ignoring dropped elements\n","    mean = calc_dropped_mean(x, mask, dims)\n","    variance = calc_dropped_var(x, mask, dims)\n","\n","    # Pad mean and variance to match the original tensor's number of dimensions\n","    mean = dimensions_pad_as(mean, x)\n","    variance = dimensions_pad_as(variance, x)\n","\n","    # Normalize the original tensor\n","    tensor_out = (x - mean) / torch.sqrt(variance + eps)\n","\n","    # Move mask to suitable device\n","    mask = mask.to(x.device)\n","\n","    # Replace dropped elements with zeros\n","    tensor_out = mask_tensor_along_axis(mask, tensor_out, dim=0)\n","\n","    return tensor_out\n"],"metadata":{"id":"grKBy9sp_3YZ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Finally, we arrive at the definition of our DropNorm layer. As we know, dropout and normalization behave differently during training compared to testing. During training, our layer operates in two phases: dropout and normalization.\n","\n","In the dropout phase, we train the gamma and beta parameters, which serve as scalars for the output from the dropout operation. Mathematically, the output (Y) is calculated as Y = gamma * dropped_tensor + beta, where Y is the final output. Initially, these parameters are set so that Y equals the dropped tensor. The dropout mask is applied to the tensor to introduce NaNs where values are dropped, and we use nan_normalize during the normalization phase to handle NaN values.\n","\n","Typically, dropout involves multiplying the input by a scaling factor during testing to account for the reduced signal strength. However, since the subsequent normalization process effectively scales the input regardless of the dropout factor, this multiplication during dropout testing does not influence the final outcome. Therefore, during testing, we proceed directly to normalization."],"metadata":{"id":"mbXSYTdG_4or"}},{"cell_type":"code","source":["class DropNorm(nn.Module):\n","    \"\"\"\n","    A custom PyTorch module implementing the DropNorm layer, which combines dropout and  sample normalization.\n","\n","    Args:\n","        input_shape (tuple): The shape of the input tensor (excluding the batch dimension).\n","        drop_rate (float, optional): The dropout rate to apply to the input tensor. Default is 0.5.\n","\n","    Attributes:\n","        gamma (nn.Parameter): Learnable scaling parameter for the normalization.\n","        beta (nn.Parameter): Learnable bias parameter for the normalization.\n","        drop_rate (float): The dropout rate applied during training.\n","\n","    Methods:\n","        __dropout(tensor): Performs the dropout phase of the DropNorm layer.\n","        forward(x): Forward pass through the DropNorm layer.\n","    \"\"\"\n","\n","    def __init__(self, input_shape, drop_rate=0.5):\n","        \"\"\"\n","        Initializes the DropNorm layer with learnable parameters.\n","\n","        Args:\n","            input_shape (tuple): The shape of the input tensor (excluding the batch dimension).\n","            drop_rate (float, optional): The dropout rate to apply to the input tensor. Default is 0.5.\n","        \"\"\"\n","        super(DropNorm, self).__init__()\n","        # Initialize parameters so y = x*gamma + beta, initially y = x\n","        self.gamma = nn.Parameter(torch.ones(input_shape))\n","        self.beta = nn.Parameter(torch.zeros(input_shape))\n","        self.drop_rate = drop_rate\n","\n","    def __dropout(self, tensor):\n","        \"\"\"\n","        Performs the dropout phase of the DropNorm layer.\n","\n","        Args:\n","            tensor (torch.Tensor): The input tensor to apply dropout to.\n","\n","        Returns:\n","            tuple: A tuple containing the tensor after dropout and the dropout mask.\n","        \"\"\"\n","        features_shape = tensor.size()[1:]  # Shape of the features excluding batch dimension\n","        mask = create_dropout_mask(features_shape, 0.5)\n","        mask = torch.reshape(mask, self.gamma.shape) # check if needed\n","        tensor_out = mask_tensor_along_axis(mask, tensor, 0)  # Apply dropout\n","        return tensor_out, mask\n","\n","    def forward(self, x):\n","        \"\"\"\n","        Forward pass through the DropNorm layer.\n","\n","        Args:\n","            x (torch.Tensor): The input tensor.\n","\n","        Returns:\n","            torch.Tensor: The output tensor after applying dropout and sample normalization.\n","        \"\"\"\n","\n","        if torch.cuda.is_available():  # Check if GPU is available\n","            device = torch.device(\"cuda\")  # Set device to GPU\n","        else:\n","            device = torch.device(\"cpu\")  # Set device to CPU\n","\n","        tensor = x.to(device).float()  # Move input tensor to device\n","\n","        if self.training:  # Training mode\n","            tensor_dropped, mask = self.__dropout(tensor)\n","            tensor_dropped_normalized = non_zero_normalize(tensor_dropped, mask=mask)\n","            y = self.gamma * tensor_dropped_normalized + self.beta\n","\n","\n","        else:  # Eval mode - no need for dropout, therefore no masking needed neither\n","            tensor_normalized = non_zero_normalize(tensor)\n","            y = self.gamma * tensor_normalized + self.beta\n","\n","        return y\n"],"metadata":{"id":"gkpZ3QPs_5kc"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Layer use example:"],"metadata":{"id":"EYb9AOPQi5L1"}},{"cell_type":"code","source":["shape = (1,5,6)\n","n_features = 1\n","for i in shape:\n","  n_features*=i\n","n_samples =  2\n","layer=DropNorm(shape).to(device)\n","my_batch = torch.rand(60).reshape(n_samples,*shape).to(device)\n","out = layer(my_batch)\n","print(out)"],"metadata":{"id":"6bnXIaBthTUm","colab":{"base_uri":"https://localhost:8080/"},"outputId":"bd23594f-129d-45c5-dd7a-1e4a82a1f016"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[[[ 0.0000,  0.0000,  0.0000,  0.0000, -0.7385,  0.0549],\n","          [ 0.0000, -0.7753,  0.0000,  0.0000,  0.3705,  0.0000],\n","          [-0.6845, -1.2659, -0.1427,  1.5324,  0.0000, -1.7282],\n","          [ 0.5783,  0.0000,  0.0000,  1.2519,  0.2735,  0.0000],\n","          [-1.1114,  0.8551,  0.0000,  0.0000,  1.5301,  0.0000]]],\n","\n","\n","        [[[ 0.0000,  0.0000,  0.0000,  0.0000, -1.0179, -1.2073],\n","          [ 0.0000,  0.6510,  0.0000,  0.0000, -1.4911,  0.0000],\n","          [-0.2317,  0.8444,  0.3089, -0.1696,  0.0000, -0.1500],\n","          [ 1.7537,  0.0000,  0.0000,  0.6660,  1.8083,  0.0000],\n","          [ 0.0454, -1.4120,  0.0000,  0.0000, -0.3981,  0.0000]]]],\n","       grad_fn=<AddBackward0>)\n"]}]},{"cell_type":"markdown","source":["# **Fashion MNIST**"],"metadata":{"id":"d2Bc9poh_6xX"}},{"cell_type":"markdown","source":["The Fashion MNIST dataset is a popular benchmark dataset widely used for training and evaluating machine learning models. It consists of a collection of grayscale images depicting various clothing items, such as shirts, dresses, shoes, and handbags. Each image is a 28x28 pixel square, resulting in a total of 784 features per sample. The dataset contains a training set of 60,000 images and a test set of 10,000 images, with each image belonging to one of ten classes. Fashion MNIST serves as a drop-in replacement for the original MNIST dataset, providing a more challenging task while maintaining the same structure and format. It is commonly used for educational purposes, prototyping machine learning algorithms, and comparing the performance of different models.\n","\n","For our experiment, we aim to compare the performance of two convolutional neural network (CNN) architectures trained on the Fashion MNIST dataset. The first CNN utilizes predefined layers from the PyTorch library for dropout and normalization, while the second CNN employs the custom DropNorm layer, which combines dropout and normalization functionalities into a single layer. This comparison allows us to evaluate the effectiveness and efficiency of the DropNorm layer in comparison to the traditional approach of using separate dropout and normalization layers."],"metadata":{"id":"7-XR9fwe_8Nx"}},{"cell_type":"code","source":["# USED GPT HERE\n","# Define transforms to normalize the data\n","transform = transforms.Compose([\n","    transforms.ToTensor(),  # Convert images to PyTorch tensors\n","])\n","\n","# Load FashionMNIST dataset\n","trainset = torchvision.datasets.FashionMNIST(root='./data', train=True, download=True, transform=transform)\n","train_size = int(0.8 * len(trainset))\n","val_size = len(trainset) - train_size\n","trainset, valset = torch.utils.data.random_split(trainset, [train_size, val_size])\n","\n","# Create data loaders for training and validation sets\n","trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True, num_workers=0)\n","valloader = torch.utils.data.DataLoader(valset, batch_size=64, shuffle=False, num_workers=0)\n","\n","# Load FashionMNIST test dataset\n","testset = torchvision.datasets.FashionMNIST(root='./data', train=False, download=True, transform=transform)\n","testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=False, num_workers=0)\n"],"metadata":{"id":"8td7iSBQ_-aj"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **Classifiers**"],"metadata":{"id":"QaIiuFy9__sS"}},{"cell_type":"markdown","source":["We've devised two neural network (CNN) architectures for our study, each serving as a contrasting approach in handling dropout and normalization. The first architecture employs standard dropout and layer normalization layers provided by the PyTorch library. In contrast, the second architecture adopts a custom layer named DropNorm, which combines both dropout and normalization functionalities into a single layer. Our objective is not to evaluate the performance of these architectures but rather to compare their behaviors and effectiveness in training on the Fashion MNIST dataset. By assessing their performance metrics, we aim to determine potential advantages or drawbacks of using the DropNorm layer over traditional dropout and normalization layers"],"metadata":{"id":"IBqmDCT8ABO7"}},{"cell_type":"code","source":["# USED GPT HERE\n","class FashionMNIST_NN(nn.Module):\n","    def __init__(self):\n","        super(FashionMNIST_NN, self).__init__()\n","        self.fc1 = nn.Linear(28 * 28, 256)\n","        self.ln1 = nn.LayerNorm(256)\n","        self.dropout1 = nn.Dropout(0.5)\n","\n","        self.fc2 = nn.Linear(256, 128)\n","        self.ln2 = nn.LayerNorm(128)\n","        self.dropout2 = nn.Dropout(0.5)\n","\n","        self.fc3 = nn.Linear(128, 64)\n","        self.ln3 = nn.LayerNorm(64)\n","        self.dropout3 = nn.Dropout(0.5)\n","\n","        self.fc4 = nn.Linear(64, 10)\n","\n","    def forward(self, x):\n","        x = x.view(-1, 28 * 28)\n","        x = F.relu(self.fc1(x))\n","        x = self.ln1(x)\n","        x = self.dropout1(x)\n","\n","        x = F.relu(self.fc2(x))\n","        x = self.ln2(x)\n","        x = self.dropout2(x)\n","\n","        x = F.relu(self.fc3(x))\n","        x = self.ln3(x)\n","        x = self.dropout3(x)\n","\n","        x = self.fc4(x)\n","        return x"],"metadata":{"id":"O3wVHkWaACAA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class MyCNN(nn.Module):\n","    \"\"\"\n","    A custom convolutional neural network (CNN) architecture with dropout and\n","    batch normalization using customized dropout and sample normalization layers\n","\n","    Methods:\n","        forward(x): Forward pass through the CNN architecture.\n","    \"\"\"\n","\n","    def __init__(self):\n","        \"\"\"\n","        Initializes the myCNN architecture with convolutional, dropout, normalization, and fully connected layers.\n","        \"\"\"\n","        super(MyCNN, self).__init__()\n","        self.fc1 = nn.Linear(28 * 28, 256)\n","        self.dropandnorm1 = DropNorm((256))\n","\n","        self.fc2 = nn.Linear(256, 128)\n","        self.dropandnorm2 = DropNorm((128))\n","\n","        self.fc3 = nn.Linear(128, 64)\n","        self.dropandnorm3 = DropNorm((64))\n","\n","        self.fc4 = nn.Linear(64, 10)\n","\n","    def forward(self, x):\n","        \"\"\"\n","        Forward pass through the MyCNN architecture.\n","\n","        Args:\n","            x (torch.Tensor): Input tensor to the network.\n","\n","        Returns:\n","            torch.Tensor: Output tensor after passing through the network.\n","        \"\"\"\n","\n","        x = x.view(-1, 28 * 28)\n","\n","        x = F.relu(self.fc1(x))\n","        x = self.dropandnorm1(x)\n","\n","        x = F.relu(self.fc2(x))\n","        x = self.dropandnorm2(x)\n","\n","        x = F.relu(self.fc3(x))\n","        x = self.dropandnorm3(x)\n","\n","        x = self.fc4(x)\n","        return x\n"],"metadata":{"id":"Lsj3yYCAAC1F"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# USED GPT HERE\n","# Set device to perform calculations on\n","dev = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","\n","# Initialize the models\n","net = FashionMNIST_NN()\n","net.to(dev)\n","net2 = MyCNN()\n","net2.to(dev)\n","\n","# Define loss function and optimizer\n","loss_criterion = nn.CrossEntropyLoss()\n","opt1 = optim.SGD(net.parameters(), lr=0.01, momentum=0.9)\n","opt2 = optim.SGD(net2.parameters(), lr=0.01, momentum=0.9)\n","\n","# Define storage paths for the best models\n","best_model_path1 = \"best_model.pth\"\n","best_model_path2 = \"best_model2.pth\""],"metadata":{"id":"3bdE7h1NAEyE"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["During the validation and testing phases of our model training, we employ the eval_model function to assess the model's performance. This function takes the trained model, the device on which to perform the evaluation, and the data loader containing either the validation or test dataset. It iterates over the dataset, computes predictions, and tracks the number of correct predictions. Finally, it calculates the accuracy of the model on the evaluation dataset and returns this value. By utilizing this function, we can effectively monitor the model's performance and make informed decisions regarding model adjustments and hyperparameter tuning."],"metadata":{"id":"LScxlXzEAFyG"}},{"cell_type":"code","source":["# USED GPT HERE\n","def eval_model(model, device, dataloader):\n","    \"\"\"\n","    Evaluate the specified model on the provided data loader.\n","\n","    Args:\n","        model (torch.nn.Module): The model to evaluate.\n","        device (torch.device): The device to use for evaluation (e.g., 'cpu' or 'cuda').\n","        dataloader (torch.utils.data.DataLoader): The data loader containing the evaluation dataset.\n","\n","    Returns:\n","        float: The accuracy of the model on the evaluation dataset.\n","\n","    \"\"\"\n","    # Set the model to evaluation mode\n","    model.eval()\n","\n","    # Initialize variables to track correct predictions and total test samples\n","    correct = 0\n","    total = 0\n","\n","    # Disable gradient calculation during evaluation\n","    with torch.no_grad():\n","        # Iterate over the test data loader\n","        for data in dataloader:\n","            # Move input data and labels to the specified device\n","            images, labels = data[0].to(device), data[1].to(device)\n","            # Forward pass\n","            outputs = model(images)\n","            # Get predicted labels\n","            _, predicted = torch.max(outputs.data, 1)\n","            # Increment the total number of test samples\n","            total += labels.size(0)\n","            # Increment the number of correct predictions\n","            correct += (predicted == labels).sum().item()\n","\n","    # Calculate the test accuracy\n","    accuracy = 100 * correct / total\n","    return accuracy"],"metadata":{"id":"uU1xUbqWAGqK"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["The train function orchestrates the training process of our neural network model. It iterates over the specified number of epochs, during which it trains the model on the training dataset and evaluates its performance on the validation dataset. Within each epoch, it computes the training loss and accuracy, and after completing an epoch, it prints these metrics along with the validation accuracy. Notably, the function dynamically saves the model with the best validation accuracy, ensuring that we retain the most optimal model configuration. This systematic approach enables us to monitor the model's training progress and ensure that it generalizes well to unseen data."],"metadata":{"id":"Vqma2iBFAHif"}},{"cell_type":"code","source":["# USED GPT HERE\n","def train(num_epochs, model, device, optimizer, criterion, best_model_out_path, train_loader, val_loader):\n","    \"\"\"\n","    Trains the given model on the training data and evaluates on the validation data.\n","\n","    Args:\n","        num_epochs (int): The number of epochs for training.\n","        model (torch.nn.Module): The neural network model to be trained.\n","        device (torch.device): The device (CPU or GPU) to be used for training.\n","        optimizer (torch.optim.Optimizer): The optimizer used for updating the model parameters.\n","        criterion (torch.nn.Module): The loss function used for computing the loss.\n","        best_model_out_path (str): The file path where the best model will be saved.\n","        train_loader (torch.utils.data.DataLoader): The DataLoader containing the training dataset.\n","        val_loader (torch.utils.data.DataLoader): The DataLoader containing the validation dataset.\n","\n","    Returns:\n","        None\n","\n","    Prints:\n","        - Training loss and accuracy for each epoch.\n","        - Validation accuracy for each epoch.\n","        - The best validation accuracy achieved during training.\n","        - \"Finished Training\" message after completing training.\n","\n","    Note:\n","        This function assumes the presence of global variables `train_loader` and `val_loader`.\n","        These should be instances of `torch.utils.data.DataLoader` containing training and validation datasets.\n","    \"\"\"\n","    # Training the network\n","\n","    best_val_accuracy = 0.0\n","    for epoch in range(num_epochs):  # Number of epochs\n","        model.train()  # Set the model to training mode\n","        running_loss = 0.0\n","        correct_train = 0\n","        total_train = 0\n","        for i, data in enumerate(train_loader, 0):\n","            inputs, labels = data[0].to(device), data[1].to(device)  # Get the inputs and labels from the training data\n","\n","            optimizer.zero_grad()  # Zero the parameter gradients\n","\n","            outputs = model(inputs)  # Forward pass: compute predicted outputs by passing inputs to the model\n","            loss = criterion(outputs, labels)  # Calculate the batch loss\n","            loss.backward()  # Backward pass: compute gradient of the loss with respect to model parameters\n","            optimizer.step()  # Perform a single optimization step (parameter update)\n","\n","            running_loss += loss.item()  # Update the running loss\n","            _, predicted = torch.max(outputs.data, 1)  # Get the predicted labels\n","            total_train += labels.size(0)  # Increment the total number of training samples\n","            correct_train += (predicted == labels).sum().item()  # Increment the number of correct predictions\n","\n","        train_accuracy = 100 * correct_train / total_train  # Calculate the training accuracy for the current epoch\n","        print(\n","            f\"Epoch {epoch + 1}, Training Loss: {running_loss / len(train_loader)}, Training Accuracy: {train_accuracy}%\")\n","\n","        val_accuracy = eval_model(model, device, val_loader)\n","        print(f\"Epoch {epoch + 1}, Validation Accuracy: {val_accuracy}%\")\n","\n","        # Save the model if it has the best validation accuracy\n","        if val_accuracy > best_val_accuracy:\n","            best_val_accuracy = val_accuracy\n","            torch.save(model.state_dict(), best_model_out_path)  # Save the model parameters\n","\n","    print(\"Finished Training\")  # Print a message indicating that training is finished\n"],"metadata":{"id":"3diDyH_XAIPm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["n_epochs = 10"],"metadata":{"id":"iHXGcRiHAJYz"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Let's train the models to obtain the best parameters"],"metadata":{"id":"lXRJnqvgAKTp"}},{"cell_type":"code","source":["train(n_epochs, net, dev, opt1, loss_criterion, best_model_path1, trainloader, valloader)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7sDCBdttALKK","outputId":"ae70cdc6-b9b3-4a92-c470-662cc06fb7ab"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1, Training Loss: 0.8830133018096288, Training Accuracy: 66.28958333333334%\n","Epoch 1, Validation Accuracy: 80.96666666666667%\n","Epoch 2, Training Loss: 0.6319848482211431, Training Accuracy: 78.01041666666667%\n","Epoch 2, Validation Accuracy: 84.41666666666667%\n","Epoch 3, Training Loss: 0.5792164388100306, Training Accuracy: 80.30208333333333%\n","Epoch 3, Validation Accuracy: 85.09166666666667%\n","Epoch 4, Training Loss: 0.538124261200428, Training Accuracy: 81.67708333333333%\n","Epoch 4, Validation Accuracy: 85.6%\n","Epoch 5, Training Loss: 0.515198551774025, Training Accuracy: 82.43958333333333%\n","Epoch 5, Validation Accuracy: 85.975%\n","Epoch 6, Training Loss: 0.4900726994673411, Training Accuracy: 83.29375%\n","Epoch 6, Validation Accuracy: 86.28333333333333%\n","Epoch 7, Training Loss: 0.4787534008224805, Training Accuracy: 83.61458333333333%\n","Epoch 7, Validation Accuracy: 86.69166666666666%\n","Epoch 8, Training Loss: 0.46695028082529705, Training Accuracy: 84.06041666666667%\n","Epoch 8, Validation Accuracy: 87.10833333333333%\n","Epoch 9, Training Loss: 0.4531964537103971, Training Accuracy: 84.50625%\n","Epoch 9, Validation Accuracy: 87.25%\n","Epoch 10, Training Loss: 0.4430698664188385, Training Accuracy: 84.8625%\n","Epoch 10, Validation Accuracy: 87.325%\n","Finished Training\n"]}]},{"cell_type":"code","source":["train(n_epochs, net2, dev, opt2, loss_criterion, best_model_path2, trainloader, valloader)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SdWAVtUAAMWL","outputId":"b23e8ae6-dfcb-4611-a855-85184c4c652a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1, Training Loss: 1.0177758386532465, Training Accuracy: 60.177083333333336%\n","Epoch 1, Validation Accuracy: 74.85833333333333%\n","Epoch 2, Training Loss: 0.683220094760259, Training Accuracy: 74.8375%\n","Epoch 2, Validation Accuracy: 81.03333333333333%\n","Epoch 3, Training Loss: 0.6134654306570689, Training Accuracy: 77.92083333333333%\n","Epoch 3, Validation Accuracy: 82.55%\n","Epoch 4, Training Loss: 0.5676774663130443, Training Accuracy: 80.15%\n","Epoch 4, Validation Accuracy: 83.34166666666667%\n","Epoch 5, Training Loss: 0.5349191464980443, Training Accuracy: 81.67291666666667%\n","Epoch 5, Validation Accuracy: 84.66666666666667%\n","Epoch 6, Training Loss: 0.5233664897680282, Training Accuracy: 81.90625%\n","Epoch 6, Validation Accuracy: 84.78333333333333%\n","Epoch 7, Training Loss: 0.502826187868913, Training Accuracy: 82.6125%\n","Epoch 7, Validation Accuracy: 85.40833333333333%\n","Epoch 8, Training Loss: 0.48584587693214415, Training Accuracy: 83.50208333333333%\n","Epoch 8, Validation Accuracy: 85.64166666666667%\n","Epoch 9, Training Loss: 0.4759234438141187, Training Accuracy: 83.54375%\n","Epoch 9, Validation Accuracy: 86.325%\n","Epoch 10, Training Loss: 0.4649516962766647, Training Accuracy: 84.0125%\n","Epoch 10, Validation Accuracy: 84.775%\n","Finished Training\n"]}]},{"cell_type":"code","source":["# Retrieve the best parameters for each of the models\n","net.load_state_dict(torch.load(best_model_path1))\n","net2.load_state_dict(torch.load(best_model_path2))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-PjpDTInAQM2","outputId":"d9256d22-b631-4604-9e19-366d52f2f9bd"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<All keys matched successfully>"]},"metadata":{},"execution_count":26}]},{"cell_type":"markdown","source":["The test function evaluates the trained neural network model on the test dataset to assess its performance on unseen data. Given the model and the test dataset, it calculates the accuracy of the model's predictions. Once the evaluation is complete, the function prints the accuracy of the model on the test images, providing insights into its overall performance. This step allows us to validate the effectiveness of the trained model and determine its ability to generalize to real-world data."],"metadata":{"id":"BM4dcJTZARLO"}},{"cell_type":"code","source":["def test(model, device, test_loader):\n","    \"\"\"\n","    Test the neural network model on the test dataset.\n","\n","    Args:\n","        model (torch.nn.Module): The neural network model to be tested.\n","        device (torch.device): The device (CPU or GPU) on which to perform testing.\n","\n","    Returns:\n","        None\n","\n","    Prints:\n","        str: The accuracy of the model on the test images.\n","    \"\"\"\n","\n","    # Calculate the test accuracy\n","    test_accuracy = eval_model(model, device, test_loader)\n","\n","    # Print the accuracy of the model on the test images\n","    print('Accuracy on the test images: %d %%' % test_accuracy)\n"],"metadata":{"id":"76hznn9RAR7l"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Finally, evaluate models on test data:"],"metadata":{"id":"k6KiApVWAS_e"}},{"cell_type":"code","source":["test(net, dev, testloader)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"629Nk6cnATxy","outputId":"67dc1d40-5005-4d14-8520-849d6f8360e1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy on the test images: 85 %\n"]}]},{"cell_type":"code","source":["test(net2, dev, testloader)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"anrZt5HSAUVe","outputId":"d23aaa0a-64a8-41de-e9bc-a2bee984422a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy on the test images: 84 %\n"]}]},{"cell_type":"markdown","source":["In this project, two CNN models were built to classify the FashionMNIST dataset. The first model used separate predefined PyTorch layers for dropout and batch normalization, achieving 85% accuracy on the test set. The second model used a custom DropNorm layer, which combines dropout and normalization in a single layer, achieving 84% accuracy.\n","\n","The predefined PyTorch layers offered greater flexibility, allowing independent use of dropout and normalization. This provided more control over their placement and tuning, potentially enhancing performance. In contrast, the DropNorm layer enforced the simultaneous use of dropout and normalization, simplifying the model but reducing customization options.\n","\n","Given the additional fluidity and control offered by the predefined layers, I would choose to use them for building neural network models, as they allow for more precise optimization and potentially better performance in complex architectures."],"metadata":{"id":"DaOxP8tnAVqO"}}]}